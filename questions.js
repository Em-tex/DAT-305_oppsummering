window.rawQuestions = [
    // === MODULE 1: INTRO (Original + New) ===
    { mod: 1, q: "Traditional programming uses Rules + Data = Answers. What is the Machine Learning (ML) paradigm?", options: ["Answers + Rules = Data", "Data + Answers = Rules", "Rules + Answers = Data", "Data = Rules"], a: 1, exp: "ML infers the rules by looking at input data and expected answers." },
    { mod: 1, q: "What is machine learning?", options: ["A method that allows computers to learn from data and make decisions", "A system that only stores large data", "A process to clean data", "Manual programming"], a: 0, exp: "It infers rules from data rather than being explicitly programmed." },
    { mod: 1, q: "Which type of learning involves an agent learning to interact with an environment to maximize a reward?", options: ["Semi-supervised", "Unsupervised", "Reinforcement learning", "Supervised"], a: 2, exp: "Think of a robot in a maze or a game AI." },
    { mod: 1, q: "Which type of learning algorithm learns from labeled data?", options: ["Semi-supervised", "Unsupervised", "Supervised learning", "Reinforcement"], a: 2, exp: "Supervised = Teacher provides the labels (answers)." },
    { mod: 1, q: "Which of the following is a common use of unsupervised learning?", options: ["Predicting house prices", "Image classification", "Clustering customers based on purchasing behavior", "Spam detection"], a: 2, exp: "Clustering finds hidden groups without pre-existing labels." },
    { mod: 1, q: "Which machine learning technique is used for making predictions on continuous data?", options: ["Clustering", "Regression", "Classification", "Association rule"], a: 1, exp: "Regression predicts numbers (e.g., Temperature, Price)." },
    { mod: 1, q: "Which of the following is an example of reinforcement learning?", options: ["Chatbot", "A robot learning to navigate a maze", "Spam filter", "Grouping documents"], a: 1, exp: "Navigation involves trial-and-error to maximize a reward." },
    { mod: 1, q: "Which of the following best describes a classification problem?", options: ["Assigning labels to data points based on features", "Grouping data into clusters", "Predicting a numerical value", "Reducing features"], a: 0, exp: "Discrete categories (e.g., Cat vs Dog)." },
    { mod: 1, q: "Which technique identifies patterns in data without using labeled responses?", options: ["Unsupervised learning", "Supervised", "Reinforcement", "Semi-supervised"], a: 0, exp: "It finds structure on its own." },
    { mod: 1, q: "What is the main difference between supervised and unsupervised learning?", options: ["Speed", "Supervised uses labeled data, unsupervised does not", "Data size", "Prediction vs Clustering"], a: 1, exp: "The presence of labels (ground truth) is the key differentiator." },
    { mod: 1, q: "Which of the following is an example of supervised learning?", options: ["Predicting next word", "Identifying topics", "Classifying images as cats or dogs", "Customer segmentation"], a: 2, exp: "The images are labeled 'Cat' or 'Dog' during training." },
    { mod: 1, q: "What best describes the concept of 'training' a model?", options: ["Using data to adjust parameters to minimize error", "Deploying to production", "Collecting data", "Testing performance"], a: 0, exp: "Training is the process of learning the weights." },
    { mod: 1, q: "What does 'generalization' mean in ML?", options: ["Ability to perform well on unseen data", "Perform well on training data", "Increasing complexity", "Simplifying model"], a: 0, exp: "The ultimate goal is to work on new, real-world data." },
    { mod: 1, q: "Which method is used to increase the generalization of a model (reduce overfitting)?", options: ["Regularization", "Increasing training set only", "Cross-validation", "Increasing features"], a: 0, exp: "Regularization penalizes complex models to prevent overfitting." },
    { mod: 1, q: "What is NumPy primarily used for?", options: ["Web Development", "Efficient N-dimensional array operations", "Data Visualization", "Database Management"], a: 1, exp: "NumPy is the foundational library for math and arrays in Python." },
    { mod: 1, q: "Which function splits data to prevent overfitting?", options: ["train_test_split()", "fit()", "predict()", "compile()"], a: 0, exp: "We must test the model on data it has never seen before." },

    // === MODULE 2: MATH & DIM REDUCTION ===
    { mod: 2, q: "If the Dot Product of two vectors is zero, they are...", options: ["Parallel", "Identical", "Orthogonal (Perpendicular)", "Opposite"], a: 2, exp: "This implies they have zero correlation (90 degree angle)." },
    { mod: 2, q: "Which of the following best describes a Square Matrix?", options: ["More rows than cols", "More cols than rows", "No rows", "Equal number of rows and columns"], a: 3, exp: "Dimensions are N x N." },
    { mod: 2, q: "What does the Dot Product between two word vectors represent?", options: ["Angle", "Length", "Similarity between the two words", "Difference"], a: 2, exp: "High dot product implies the vectors point in the same direction (Similar meaning)." },
    { mod: 2, q: "What is the correct order of Principal Component Analysis (PCA) steps?", options: ["Project -> Eigen -> Covariance -> Standardize", "Standardize -> Covariance -> Eigen -> Project", "Covariance -> Standardize -> Project -> Eigen", "Standardize -> Project -> Covariance"], a: 1, exp: "We must Standardize first, then find relationships (Covariance), then directions (Eigen), then Project." },
    { mod: 2, q: "Which algorithm is commonly used for dimensionality reduction?", options: ["PCA (Principal Component Analysis)", "Decision Tree", "K-Means", "Linear Regression"], a: 0, exp: "PCA projects data to lower dimensions." },
    { mod: 2, q: "What does 'explained variance' mean in PCA?", options: ["Unexplained variance", "Noise variance", "Total variance", "The amount of variance captured by each principal component"], a: 3, exp: "It tells you how much information that component holds." },
    { mod: 2, q: "Why do we Standardize data before PCA?", options: ["To remove colors", "To make all features contribute equally", "To increase variance", "To make data smaller"], a: 1, exp: "If one feature ranges 0-1000 and another 0-1, the large one will dominate variance without standardization." },
    { mod: 2, q: "Which is an advantage of dimensionality reduction?", options: ["No training set needed", "Reduces computational cost and complexity", "Always improves accuracy", "Auto labeling"], a: 1, exp: "Fewer features = Faster training and less memory." },
    { mod: 2, q: "Which algorithm is commonly used for collaborative filtering in recommendation systems?", options: ["K-Means", "Apriori", "Matrix Factorization", "Decision Tree"], a: 2, exp: "It predicts missing ratings by decomposing the matrix." },
    { mod: 2, q: "What is the goal of matrix factorization?", options: ["Increase dimensions", "Solve regression", "Decompose a matrix into lower-dimensional matrices", "Create new features"], a: 2, exp: "Breaking a big matrix into smaller factors (Users and Items)." },
    { mod: 2, q: "Which algorithm is commonly used for matrix factorization?", options: ["Naive Bayes", "Decision Tree", "K-Means", "Singular Value Decomposition (SVD)"], a: 3, exp: "SVD is the standard mathematical method for this." },
    { mod: 2, q: "What is the main advantage of Matrix Factorization for recommendation?", options: ["Handles sparse data effectively", "Requires large labeled data", "Perfect predictions", "Simplest to implement"], a: 0, exp: "It works well even if the user has only watched 5 out of 10,000 movies." },
    { mod: 2, q: "One-Hot Encoding converts 'Red' into...", options: ["1", "[1, 0, 0]", "0.5", "Red"], a: 1, exp: "It creates a sparse binary vector." },

    // === MODULE 3: ALGORITHMS & EVAL ===
    { mod: 3, q: "Linear Regression minimizes which cost function?", options: ["Accuracy", "MSE (Mean Squared Error)", "Entropy", "F1 Score"], a: 1, exp: "It minimizes the average squared distance between points and the line." },
    { mod: 3, q: "Which evaluation metric is a common choice for regression models?", options: ["Recall", "Precision", "Mean Squared Error (MSE)", "F1-Score"], a: 2, exp: "MSE measures the average squared difference between predicted and actual values." },
    { mod: 3, q: "Which evaluation metric is most appropriate for multi-class classification?", options: ["Adjusted R-squared", "MSE", "MAE", "Accuracy"], a: 3, exp: "Accuracy is the standard baseline for multi-class problems." },
    { mod: 3, q: "Which type of problem is best suited for Support Vector Machines (SVM)?", options: ["Regression", "Clustering", "Dimensionality Reduction", "Classification"], a: 3, exp: "SVM is primarily a classifier finding the optimal margin." },
    { mod: 3, q: "What is the purpose of using a 'kernel' in SVM?", options: ["Increase data size", "Reduce features", "Handle non-linear data", "Normalize data"], a: 2, exp: "It maps data to higher dimensions to make it linearly separable." },
    { mod: 3, q: "What is a characteristic of a linear model?", options: ["Always better", "Requires huge data", "Captures non-linear relationships", "Assumes a linear relationship between input and output"], a: 3, exp: "It fits a straight line (or hyperplane)." },
    { mod: 3, q: "What does the term 'confusion matrix' refer to?", options: ["Dim reduction", "Normalization", "Cluster viz", "A table used to describe the performance of a classification model"], a: 3, exp: "Shows True Positives, False Positives, etc." },
    { mod: 3, q: "In KNN, a small 'K' (e.g., K=1) usually leads to...", options: ["Underfitting", "Overfitting (sensitive to noise)", "Perfect accuracy", "Faster speed"], a: 1, exp: "With K=1, the model simply memorizes the nearest point, capturing noise." },
    { mod: 3, q: "Recall (Sensitivity) is calculated as...", options: ["TP / (TP + FP)", "TP / (TP + FN)", "(TP + TN) / Total", "TN / (TN + FP)"], a: 1, exp: "It measures the percentage of Actual Positives that were correctly identified." },
    { mod: 3, q: "Which metric is best for imbalanced datasets (e.g., 99% healthy, 1% sick)?", options: ["Accuracy", "MSE", "F1-Score / AUC", "None"], a: 2, exp: "Accuracy is misleading here (99% accuracy by predicting 'Healthy' every time)." },
    { mod: 3, q: "Decision Trees split data to maximize...", options: ["Entropy", "Information Gain", "Error", "Variance"], a: 1, exp: "They try to reduce Entropy (randomness) at each step." },
    { mod: 3, q: "K-Means is what type of algorithm?", options: ["Supervised Classification", "Unsupervised Clustering", "Reinforcement", "Regression"], a: 1, exp: "It groups data without labels." },

    // === MODULE 4: ANN ===
    { mod: 4, q: "What is the primary function of an activation function?", options: ["Initialize weights", "Adjust learning rate", "Introduce non-linearity", "Propagate error"], a: 2, exp: "Allows the network to learn complex patterns." },
    { mod: 4, q: "What is the role of the input layer?", options: ["Store weights", "Perform computation", "Process input", "Pass the input data to the network"], a: 3, exp: "It's just the entry point, no calculation happens here." },
    { mod: 4, q: "What best describes a hidden layer?", options: ["Layer where learning and pattern extraction occurs", "Output layer", "Adjusts learning rate", "Receives input directly"], a: 0, exp: "It is 'hidden' between input and output." },
    { mod: 4, q: "What is the role of weights?", options: ["Control input amount", "Activate neurons", "Combine inputs and pass to activation function", "Init structure"], a: 2, exp: "They determine the strength of the connection." },
    { mod: 4, q: "Which activation function is commonly used in hidden layers?", options: ["ReLU", "Sigmoid", "Linear", "Softmax"], a: 0, exp: "ReLU is the standard default." },
    { mod: 4, q: "Which function causes Vanishing Gradient in deep nets?", options: ["ReLU", "Sigmoid", "Leaky ReLU", "Linear"], a: 1, exp: "Its derivative is always < 0.25, causing gradients to shrink to zero." },
    { mod: 4, q: "How are weights typically updated during training?", options: ["Randomly", "Fixed", "Using error from loss function", "Using input values"], a: 2, exp: "The gradient of the loss function dictates the update." },
    { mod: 4, q: "What is backpropagation?", options: ["Adding layers", "Forward pass", "Algorithm to update weights based on error", "Init weights"], a: 2, exp: "Propagating the error backwards." },
    { mod: 4, q: "Backpropagation uses ______ to calculate gradients.", options: ["The Chain Rule", "Integration", "Matrix Inversion", "Random Guessing"], a: 0, exp: "It propagates error backwards layer by layer." },
    { mod: 4, q: "What describes a fully connected layer?", options: ["Dropout applied", "Each neuron connected to every neuron in previous layer", "Subset connection", "No activation"], a: 1, exp: "Dense connections." },
    { mod: 4, q: "What is the purpose of the loss function?", options: ["Decide activation", "Determine structure", "Init weights", "Measure difference between predicted and actual output"], a: 3, exp: "It quantifies how 'bad' the model is." },
    { mod: 4, q: "What does 'epoch' refer to?", options: ["Neurons count", "Single update", "A complete pass through the entire training dataset", "Layer count"], a: 2, exp: "One cycle through all data." },
    { mod: 4, q: "The 'Bias' in a neuron acts like...", options: ["The slope", "The y-intercept (shift)", "The weight", "The input"], a: 1, exp: "It allows the activation function to shift left or right." },
    { mod: 4, q: "If Learning Rate is too high...", options: ["Convergence is slow", "The model might diverge/overshoot", "It is perfect", "The model stops"], a: 1, exp: "Like taking too big a step down a hill and falling over the other side." },

    // === MODULE 5: DL ===
    { mod: 5, q: "What is deep learning?", options: ["Shallow models", "Reduce complexity", "Algorithms using multiple layers of neurons", "One hidden layer"], a: 2, exp: "Deep = Many layers." },
    { mod: 5, q: "What is an advantage of deep learning models?", options: ["Require little data", "Automatically extract features from raw data", "Easy to interpret", "Fewer parameters"], a: 1, exp: "No manual feature engineering needed." },
    { mod: 5, q: "What is the 'vanishing gradient problem' associated with?", options: ["Training deep neural networks", "Fully connected", "Shallow nets", "CNNs"], a: 0, exp: "Gradients become too small to update weights in early layers." },
    { mod: 5, q: "Primary purpose of a convolutional layer?", options: ["Reduce dim", "Capture spatial features", "Apply non-linearity", "Fully connect"], a: 1, exp: "Detects edges, shapes, and textures." },
    { mod: 5, q: "Role of the pooling layer?", options: ["Activation", "Increase params", "Dot product", "Reduce spatial dimensions"], a: 3, exp: "Down-sampling to reduce computation." },
    { mod: 5, q: "Which pooling is most common?", options: ["Sum", "Min", "Max pooling", "Average"], a: 2, exp: "Taking the maximum value in the window." },
    { mod: 5, q: "For which data are RNNs well-suited?", options: ["Images", "Tabular", "Sequential (Time series/Text)", "Categorical"], a: 2, exp: "Data where order matters." },
    { mod: 5, q: "True about LSTM cell state?", options: ["Does not change", "Final output", "Same as hidden", "Updated at each step, carries long-term info"], a: 3, exp: "The 'highway' for information flow." },
    { mod: 5, q: "Primary purpose of an autoencoder?", options: ["Increase features", "Classify", "Generate new data", "Reduce dimensionality while retaining features"], a: 3, exp: "Compression and reconstruction." },
    { mod: 5, q: "What is the 'bottleneck' layer in an autoencoder?", options: ["Input", "Layer with smallest number of neurons", "Output", "Reconstruction"], a: 1, exp: "Forces the model to learn a compressed representation." },
    { mod: 5, q: "Which is NOT a gate in LSTM?", options: ["Forget", "Input", "Output", "Window"], a: 3, exp: "Window is a concept, not a gate." },
    { mod: 5, q: "What is Transfer Learning?", options: ["Copying homework", "Using a pre-trained model on a new task", "Training from scratch", "Unsupervised learning"], a: 1, exp: "Using a model trained on ImageNet to classify your own specific photos." },

    // === MODULE 6: NLP ===
    { mod: 6, q: "Primary goal of NLP?", options: ["Understand/interpret/generate human language", "Generate images", "Optimize equations", "Build NN"], a: 0, exp: "Bridging human language and computers." },
    { mod: 6, q: "Example of an NLP task?", options: ["Predicting prices", "Sentiment analysis", "Object detection", "Movie rec"], a: 1, exp: "Determining if text is positive or negative." },
    { mod: 6, q: "What is tokenization?", options: ["Lowercase", "Remove stop words", "Stemming", "Dividing text into smaller parts (words)"], a: 3, exp: "Breaking text into units." },
    { mod: 6, q: "What is lemmatization?", options: ["Lowercase", "Converting words to root form", "Remove punctuation", "Tokenizing"], a: 1, exp: "Better than stemming (Running -> Run)." },
    { mod: 6, q: "What does Term Frequency (TF) measure?", options: ["Rarity", "Frequency of a term in a document", "Importance", "Length"], a: 1, exp: "How often a word appears in the specific text." },
    { mod: 6, q: "What does 'word embedding' refer to?", options: ["Document vector", "Sentence matrix", "Single word vector", "Frequency vector"], a: 2, exp: "A dense vector capturing semantic meaning." },
    { mod: 6, q: "Main innovation of Transformer model?", options: ["Recurrent connections", "Conv layers", "Attention mechanisms", "Deep belief"], a: 2, exp: "Allows focusing on relevant parts of input." },
    { mod: 6, q: "Purpose of multi-head attention?", options: ["Reduce cost", "Apply multiple attention mechanisms in parallel", "Normalize", "Increase depth"], a: 1, exp: "Captures different types of relationships simultaneously." },
    { mod: 6, q: "Task improved by Transformers?", options: ["Forecasting", "Image class", "Clustering", "Machine translation"], a: 3, exp: "Google Translate improved massively with Transformers." },
    { mod: 6, q: "Difference between BERT and original Transformer?", options: ["BERT uses RNN", "BERT is image only", "BERT uses Conv", "BERT uses only the encoder part"], a: 3, exp: "It is bi-directional and encoder-only." },
    { mod: 6, q: "Technique to convert categorical data to vectors?", options: ["One-hot encoding", "Linear Reg", "SVD", "Gradient"], a: 0, exp: "Creates binary columns." },
    { mod: 6, q: "TF-IDF highlights words that are...", options: ["Common everywhere", "Rare in the corpus but frequent in the document", "Short", "Long"], a: 1, exp: "These are usually the keywords." },
    { mod: 6, q: "GPT (Generative Pre-trained Transformer) is...", options: ["Encoder-only", "Decoder-only (Autoregressive)", "For classification", "Small"], a: 1, exp: "It predicts the next word (Generative)." },
    { mod: 6, q: "Stop Words are...", options: ["Keywords", "Common words removed (the, a)", "Ending punctuation", "Errors"], a: 1, exp: "They add noise but little meaning." },

    // === MODULE 7: APPLIED/CODE (Original) ===
    { mod: 7, q: "What is the shape of <code>np.zeros((3, 4))</code>?", options: ["(4, 3)", "(3, 4)", "(12)", "(7)"], a: 1, exp: "It creates a matrix with 3 rows and 4 columns." },
    { mod: 7, q: "How do you check for missing values in Pandas?", options: ["df.missing()", "df.isnull().sum()", "df.check()", "df.void()"], a: 1, exp: "<code>isnull()</code> returns True for missing data." },
    { mod: 7, q: "Which Keras method trains the model?", options: ["model.compile()", "model.fit()", "model.evaluate()", "model.predict()"], a: 1, exp: "<code>fit()</code> adapts the weights to the data." },
    { mod: 7, q: "What does <code>model.add(Dense(32, activation='relu'))</code> do?", options: ["Adds a convolutional layer", "Adds a fully connected layer with 32 neurons", "Adds an output layer", "Compiles the model"], a: 1, exp: "Dense means Fully Connected." },
    { mod: 7, q: "In Python, <code>arr[-1]</code> refers to...", options: ["The first element", "The last element", "An error", "The second element"], a: 1, exp: "Negative indexing counts from the end." },
    { mod: 7, q: "Which function is used to convert categorical text to numbers?", options: ["StandardScaler", "LabelEncoder", "MinMaxScaler", "LinearRegression"], a: 1, exp: "LabelEncoder turns ['Cat', 'Dog'] into [0, 1]." },
    { mod: 7, q: "The output of <code>np.array([1, 2]) * 3</code> is...", options: ["[1, 2, 1, 2, 1, 2]", "[3, 6]", "Error", "[1, 2, 3]"], a: 1, exp: "NumPy uses vectorization (element-wise multiplication)." },
    { mod: 7, q: "What does <code>random_state=42</code> ensure?", options: ["Better accuracy", "Reproducibility (same random split every time)", "Faster training", "Nothing"], a: 1, exp: "It sets the seed for the random number generator." },
    { mod: 7, q: "To load a CSV file, you use...", options: ["np.load_csv()", "pd.read_csv()", "csv.get()", "pd.csv()"], a: 1, exp: "Pandas standard function." },
    { mod: 7, q: "What is the result of <code>len([1, 2, 3])</code>?", options: ["2", "3", "4", "0"], a: 1, exp: "Returns the number of items in the list." },
    { mod: 7, q: "In Keras, <code>input_shape=(28, 28, 1)</code> defines...", options: ["A color image", "A 1D vector", "A grayscale image of 28x28", "A video"], a: 2, exp: "Height 28, Width 28, Channels 1 (Grayscale)." },
    { mod: 7, q: "What does <code>df.head()</code> do?", options: ["Shows the first 5 rows", "Shows the headers", "Shows the last 5 rows", "Deletes the top row"], a: 0, exp: "Useful for a quick data inspection." },
    { mod: 7, q: "Which library is built on top of NumPy?", options: ["Pandas", "React", "Django", "Flask"], a: 0, exp: "Pandas relies heavily on NumPy arrays." },
    { mod: 7, q: "To reshape a 1D array of 10 elements to 2x5, use...", options: ["arr.resize(2,5)", "arr.reshape(2,5)", "arr.split(2)", "arr.transform(2,5)"], a: 1, exp: "Reshape changes dimensions without changing data." },
    { mod: 7, q: "What does <code>plt.plot(x, y)</code> do in Matplotlib?", options: ["Scatters points", "Draws a line chart", "Draws a bar chart", "Shows an image"], a: 1, exp: "The standard function for line plots." }
];